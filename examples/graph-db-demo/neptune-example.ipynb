{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neptune as Graph Memory\n",
    "\n",
    "In this notebook, we will be connecting using a Amazon Neptune DC Cluster instance as our memory graph storage for Mem0.\n",
    "\n",
    "The Graph Memory storage persists memories in a graph or relationship form when performing `m.add` memory operations. It then uses vector distance algorithms to find related memories during a `m.search` operation. Relationships are returned in the result, and add context to the memories.\n",
    "\n",
    "Reference: [Vector Similarity using Neptune Analytics](https://docs.aws.amazon.com/neptune-analytics/latest/userguide/vector-similarity.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "### 1. Install Mem0 with Graph Memory support \n",
    "\n",
    "To use Mem0 with Graph Memory support (as well as other Amazon services), use pip install:\n",
    "\n",
    "```bash\n",
    "pip install \"mem0ai[graph,extras]\"\n",
    "```\n",
    "\n",
    "This command installs Mem0 along with the necessary dependencies for graph functionality (`graph`) and other Amazon dependencies (`extras`).\n",
    "\n",
    "### 2. Connect to Amazon services\n",
    "\n",
    "For this sample notebook, configure `mem0ai` with [Amazon Neptune Analytics](https://docs.aws.amazon.com/neptune-analytics/latest/userguide/what-is-neptune-analytics.html) as the graph store, [Amazon OpenSearch Serverless](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/serverless-overview.html) as the vector store, and [Amazon Bedrock](https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html) for generating embeddings.\n",
    "\n",
    "Use the following guide for setup details: [Setup AWS Bedrock, AOSS, and Neptune](https://docs.mem0.ai/examples/aws_example#aws-bedrock-and-aoss)\n",
    "\n",
    "Your configuration should look similar to:\n",
    "\n",
    "```python\n",
    "config = {\n",
    "    \"embedder\": {\n",
    "        \"provider\": \"aws_bedrock\",\n",
    "        \"config\": {\n",
    "            \"model\": \"amazon.titan-embed-text-v2:0\"\n",
    "        }\n",
    "    },\n",
    "    \"llm\": {\n",
    "        \"provider\": \"aws_bedrock\",\n",
    "        \"config\": {\n",
    "            \"model\": \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "            \"temperature\": 0.1,\n",
    "            \"max_tokens\": 2000\n",
    "        }\n",
    "    },\n",
    "    \"vector_store\": {\n",
    "        \"provider\": \"opensearch\",\n",
    "        \"config\": {\n",
    "            \"collection_name\": \"mem0\",\n",
    "            \"host\": \"your-opensearch-domain.us-west-2.es.amazonaws.com\",\n",
    "            \"port\": 443,\n",
    "            \"http_auth\": auth,\n",
    "            \"connection_class\": RequestsHttpConnection,\n",
    "            \"pool_maxsize\": 20,\n",
    "            \"use_ssl\": True,\n",
    "            \"verify_certs\": True,\n",
    "            \"embedding_model_dims\": 1024,\n",
    "        }\n",
    "    },\n",
    "    \"graph_store\": {\n",
    "        \"provider\": \"neptune\",\n",
    "        \"config\": {\n",
    "            \"endpoint\": f\"neptune-graph://my-graph-identifier\",\n",
    "        },\n",
    "    },\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import all packages and setup logging"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T20:51:24.854730Z",
     "start_time": "2025-09-02T20:51:20.879466Z"
    }
   },
   "source": [
    "from mem0 import Memory\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import boto3\n",
    "from opensearchpy import RequestsHttpConnection, AWSV4SignerAuth\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "logging.getLogger(\"mem0.graphs.neptune.neptunedb\").setLevel(logging.DEBUG)\n",
    "logging.getLogger(\"mem0.graphs.neptune.base\").setLevel(logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    stream=sys.stdout,  # Explicitly set output to stdout\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the Mem0 configuration using:\n",
    "- Amazon Bedrock as the embedder\n",
    "- Amazon Neptune Analytics instance as a graph store\n",
    "- OpenSearch as the vector store"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T20:51:25.187402Z",
     "start_time": "2025-09-02T20:51:25.172301Z"
    }
   },
   "source": [
    "bedrock_embedder_model = \"amazon.titan-embed-text-v2:0\"\n",
    "bedrock_llm_model = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    "embedding_model_dims = 1024\n",
    "\n",
    "neptune_host = os.environ.get(\"GRAPH_HOST\")\n",
    "\n",
    "opensearch_host = os.environ.get(\"OS_HOST\")\n",
    "opensearch_port = 443\n",
    "\n",
    "credentials = boto3.Session().get_credentials()\n",
    "region = os.environ.get(\"AWS_REGION\")\n",
    "auth = AWSV4SignerAuth(credentials, region)\n",
    "\n",
    "config = {\n",
    "    \"embedder\": {\n",
    "        \"provider\": \"aws_bedrock\",\n",
    "        \"config\": {\n",
    "            \"model\": bedrock_embedder_model,\n",
    "        }\n",
    "    },\n",
    "    \"llm\": {\n",
    "        \"provider\": \"aws_bedrock\",\n",
    "        \"config\": {\n",
    "            \"model\": bedrock_llm_model,\n",
    "            \"temperature\": 0.1,\n",
    "            \"max_tokens\": 2000\n",
    "        }\n",
    "    },\n",
    "    \"vector_store\": {\n",
    "        \"provider\": \"opensearch\",\n",
    "        \"config\": {\n",
    "            \"collection_name\": \"mem0ai_vector_store\",\n",
    "            \"host\": opensearch_host,\n",
    "            \"port\": opensearch_port,\n",
    "            \"http_auth\": auth,\n",
    "            \"embedding_model_dims\": embedding_model_dims,\n",
    "            \"use_ssl\": True,\n",
    "            \"verify_certs\": True,\n",
    "            \"connection_class\": RequestsHttpConnection,\n",
    "        },\n",
    "    },\n",
    "    \"graph_store\": {\n",
    "        \"provider\": \"neptunedb\",\n",
    "        \"config\": {\n",
    "            \"endpoint\": f\"neptune-db://{neptune_host}\",\n",
    "        },\n",
    "    },\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Memory initializiation\n",
    "\n",
    "Initialize Memgraph as a Graph Memory store:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T20:52:10.931448Z",
     "start_time": "2025-09-02T20:51:51.077833Z"
    }
   },
   "source": [
    "m = Memory.from_config(config_dict=config)\n",
    "\n",
    "app_id = \"movies\"\n",
    "user_id = \"alice\"\n",
    "\n",
    "m.delete_all(user_id=user_id)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING - Resetting index mem0ai_vector_store...\n",
      "WARNING - Creating index mem0ai_vector_store, it might take 1-2 minutes...\n",
      "WARNING - Resetting index mem0ai_vector_store_neptune_vector_store...\n",
      "WARNING - Creating index mem0ai_vector_store_neptune_vector_store, it might take 1-2 minutes...\n",
      "DEBUG - delete_all query=\n",
      "        MATCH (n  {user_id: $user_id})\n",
      "        DETACH DELETE n\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Memories deleted successfully!'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store memories\n",
    "\n",
    "Create memories and store one at a time:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T20:52:29.692018Z",
     "start_time": "2025-09-02T20:52:13.266780Z"
    }
   },
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"I'm planning to watch a movie tonight. Any recommendations?\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Store inferred memories (default behavior)\n",
    "result = m.add(messages, user_id=user_id, metadata={\"category\": \"movie_recommendations\"})\n",
    "\n",
    "all_results = m.get_all(user_id=user_id)\n",
    "for n in all_results[\"results\"]:\n",
    "    print(f\"node \\\"{n['memory']}\\\": [hash: {n['hash']}]\")\n",
    "\n",
    "for e in all_results[\"relations\"]:\n",
    "    print(f\"edge \\\"{e['source']}\\\" --{e['relationship']}--> \\\"{e['target']}\\\"\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG - Extracted entities: [{'source': 'alice', 'relationship': 'plans_to_watch', 'destination': 'movie'}]\n",
      "DEBUG - _search_graph_db\n",
      "  query=\n",
      "            MATCH (n )-[r]->(m)\n",
      "            WHERE n.user_id = $user_id AND id(n) IN $n_ids\n",
      "            RETURN n.name AS source, id(n) AS source_id, type(r) AS relationship, id(r) AS relation_id, m.name AS destination, id(m) AS destination_id\n",
      "            UNION\n",
      "            MATCH (m)-[r]->(n ) \n",
      "            RETURN m.name AS source, id(m) AS source_id, type(r) AS relationship, id(r) AS relation_id, n.name AS destination, id(n) AS destination_id\n",
      "            LIMIT $limit\n",
      "        \n",
      "DEBUG - _search_graph_db\n",
      "  query=\n",
      "            MATCH (n )-[r]->(m)\n",
      "            WHERE n.user_id = $user_id AND id(n) IN $n_ids\n",
      "            RETURN n.name AS source, id(n) AS source_id, type(r) AS relationship, id(r) AS relation_id, m.name AS destination, id(m) AS destination_id\n",
      "            UNION\n",
      "            MATCH (m)-[r]->(n ) \n",
      "            RETURN m.name AS source, id(m) AS source_id, type(r) AS relationship, id(r) AS relation_id, n.name AS destination, id(n) AS destination_id\n",
      "            LIMIT $limit\n",
      "        \n",
      "DEBUG - Deleted relationships: []\n",
      "DEBUG - _search_source_node\n",
      "  query=\n",
      "            MATCH (source_candidate )\n",
      "            WHERE source_candidate.user_id = $user_id AND id(source_candidate) IN $ids\n",
      "            RETURN id(source_candidate)\n",
      "            \n",
      "DEBUG - _search_destination_node\n",
      "  query=\n",
      "            MATCH (destination_candidate )\n",
      "            WHERE destination_candidate.user_id = $user_id AND id(destination_candidate) IN $ids\n",
      "            RETURN id(destination_candidate)\n",
      "            \n",
      "DEBUG - _add_new_entities_cypher:\n",
      "  query=\n",
      "                MERGE (n :`person` {name: $source_name, user_id: $user_id, ~id: $source_id})\n",
      "                ON CREATE SET n.created = timestamp(),\n",
      "                              n.mentions = 1\n",
      "                              \n",
      "                ON MATCH SET n.mentions = coalesce(n.mentions, 0) + 1\n",
      "                WITH n\n",
      "                MERGE (m :`entertainment` {name: $dest_name, user_id: $user_id, , ~id: $dest_id})\n",
      "                ON CREATE SET m.created = timestamp(),\n",
      "                              m.mentions = 1\n",
      "                              \n",
      "                ON MATCH SET m.mentions = coalesce(m.mentions, 0) + 1\n",
      "                WITH n, m\n",
      "                MERGE (n)-[rel:plans_to_watch]->(m)\n",
      "                ON CREATE SET rel.created = timestamp(), rel.mentions = 1\n",
      "                ON MATCH SET rel.mentions = coalesce(rel.mentions, 0) + 1\n",
      "                RETURN n.name AS source, type(rel) AS relationship, m.name AS target\n",
      "                \n"
     ]
    },
    {
     "ename": "NeptuneQueryException",
     "evalue": "{'message': 'An error occurred while executing the query.', 'details': \"An error occurred (MalformedQueryException) when calling the ExecuteOpenCypherQuery operation: Invalid input '~': expected whitespace, comment or a property key name (line 2, column 76 (offset: 76))\"}",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mMalformedQueryException\u001B[39m                   Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~/git/acarbonetto/mem0/.venv/lib/python3.11/site-packages/langchain_aws/graphs/neptune_graph.py:462\u001B[39m, in \u001B[36mNeptuneGraph.query\u001B[39m\u001B[34m(self, query, params)\u001B[39m\n\u001B[32m    461\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m params:\n\u001B[32m--> \u001B[39m\u001B[32m462\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mclient\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexecute_open_cypher_query\u001B[49m\u001B[43m(\u001B[49m\u001B[43mopenCypherQuery\u001B[49m\u001B[43m=\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mjson\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdumps\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m[\n\u001B[32m    463\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mresults\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    464\u001B[39m     ]\n\u001B[32m    465\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/git/acarbonetto/mem0/.venv/lib/python3.11/site-packages/botocore/client.py:602\u001B[39m, in \u001B[36mClientCreator._create_api_method.<locals>._api_call\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    601\u001B[39m \u001B[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m602\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_make_api_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43moperation_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/git/acarbonetto/mem0/.venv/lib/python3.11/site-packages/botocore/context.py:123\u001B[39m, in \u001B[36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    122\u001B[39m     hook()\n\u001B[32m--> \u001B[39m\u001B[32m123\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/git/acarbonetto/mem0/.venv/lib/python3.11/site-packages/botocore/client.py:1078\u001B[39m, in \u001B[36mBaseClient._make_api_call\u001B[39m\u001B[34m(self, operation_name, api_params)\u001B[39m\n\u001B[32m   1077\u001B[39m     error_class = \u001B[38;5;28mself\u001B[39m.exceptions.from_code(error_code)\n\u001B[32m-> \u001B[39m\u001B[32m1078\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m error_class(parsed_response, operation_name)\n\u001B[32m   1079\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[31mMalformedQueryException\u001B[39m: An error occurred (MalformedQueryException) when calling the ExecuteOpenCypherQuery operation: Invalid input '~': expected whitespace, comment or a property key name (line 2, column 76 (offset: 76))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mNeptuneQueryException\u001B[39m                     Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      1\u001B[39m messages = [\n\u001B[32m      2\u001B[39m     {\n\u001B[32m      3\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mrole\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33muser\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m      4\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mcontent\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33mI\u001B[39m\u001B[33m'\u001B[39m\u001B[33mm planning to watch a movie tonight. Any recommendations?\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m      5\u001B[39m     },\n\u001B[32m      6\u001B[39m ]\n\u001B[32m      8\u001B[39m \u001B[38;5;66;03m# Store inferred memories (default behavior)\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m result = \u001B[43mm\u001B[49m\u001B[43m.\u001B[49m\u001B[43madd\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muser_id\u001B[49m\u001B[43m=\u001B[49m\u001B[43muser_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m=\u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcategory\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmovie_recommendations\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     11\u001B[39m all_results = m.get_all(user_id=user_id)\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m n \u001B[38;5;129;01min\u001B[39;00m all_results[\u001B[33m\"\u001B[39m\u001B[33mresults\u001B[39m\u001B[33m\"\u001B[39m]:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/git/acarbonetto/mem0/mem0/memory/main.py:265\u001B[39m, in \u001B[36mMemory.add\u001B[39m\u001B[34m(self, messages, user_id, agent_id, run_id, metadata, infer, memory_type, prompt)\u001B[39m\n\u001B[32m    262\u001B[39m     concurrent.futures.wait([future1, future2])\n\u001B[32m    264\u001B[39m     vector_store_result = future1.result()\n\u001B[32m--> \u001B[39m\u001B[32m265\u001B[39m     graph_result = \u001B[43mfuture2\u001B[49m\u001B[43m.\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    267\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.api_version == \u001B[33m\"\u001B[39m\u001B[33mv1.0\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    268\u001B[39m     warnings.warn(\n\u001B[32m    269\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mThe current add API output format is deprecated. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    270\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mTo use the latest format, set `api_version=\u001B[39m\u001B[33m'\u001B[39m\u001B[33mv1.1\u001B[39m\u001B[33m'\u001B[39m\u001B[33m`. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   (...)\u001B[39m\u001B[32m    273\u001B[39m         stacklevel=\u001B[32m2\u001B[39m,\n\u001B[32m    274\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:449\u001B[39m, in \u001B[36mFuture.result\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    447\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[32m    448\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._state == FINISHED:\n\u001B[32m--> \u001B[39m\u001B[32m449\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    451\u001B[39m \u001B[38;5;28mself\u001B[39m._condition.wait(timeout)\n\u001B[32m    453\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:401\u001B[39m, in \u001B[36mFuture.__get_result\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    399\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._exception:\n\u001B[32m    400\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m401\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._exception\n\u001B[32m    402\u001B[39m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    403\u001B[39m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[32m    404\u001B[39m         \u001B[38;5;28mself\u001B[39m = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py:58\u001B[39m, in \u001B[36m_WorkItem.run\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     55\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m     57\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m58\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     59\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m     60\u001B[39m     \u001B[38;5;28mself\u001B[39m.future.set_exception(exc)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/git/acarbonetto/mem0/mem0/memory/main.py:461\u001B[39m, in \u001B[36mMemory._add_to_graph\u001B[39m\u001B[34m(self, messages, filters)\u001B[39m\n\u001B[32m    458\u001B[39m         filters[\u001B[33m\"\u001B[39m\u001B[33muser_id\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[33m\"\u001B[39m\u001B[33muser\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    460\u001B[39m     data = \u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m.join([msg[\u001B[33m\"\u001B[39m\u001B[33mcontent\u001B[39m\u001B[33m\"\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m msg \u001B[38;5;129;01min\u001B[39;00m messages \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mcontent\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m msg \u001B[38;5;129;01mand\u001B[39;00m msg[\u001B[33m\"\u001B[39m\u001B[33mrole\u001B[39m\u001B[33m\"\u001B[39m] != \u001B[33m\"\u001B[39m\u001B[33msystem\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m--> \u001B[39m\u001B[32m461\u001B[39m     added_entities = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgraph\u001B[49m\u001B[43m.\u001B[49m\u001B[43madd\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilters\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    463\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m added_entities\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/git/acarbonetto/mem0/mem0/graphs/neptune/base.py:72\u001B[39m, in \u001B[36mNeptuneBase.add\u001B[39m\u001B[34m(self, data, filters)\u001B[39m\n\u001B[32m     69\u001B[39m to_be_deleted = \u001B[38;5;28mself\u001B[39m._get_delete_entities_from_search_output(search_output, data, filters)\n\u001B[32m     71\u001B[39m deleted_entities = \u001B[38;5;28mself\u001B[39m._delete_entities(to_be_deleted, filters[\u001B[33m\"\u001B[39m\u001B[33muser_id\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m---> \u001B[39m\u001B[32m72\u001B[39m added_entities = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_add_entities\u001B[49m\u001B[43m(\u001B[49m\u001B[43mto_be_added\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilters\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43muser_id\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mentity_type_map\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     74\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[33m\"\u001B[39m\u001B[33mdeleted_entities\u001B[39m\u001B[33m\"\u001B[39m: deleted_entities, \u001B[33m\"\u001B[39m\u001B[33madded_entities\u001B[39m\u001B[33m\"\u001B[39m: added_entities}\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/git/acarbonetto/mem0/mem0/graphs/neptune/base.py:252\u001B[39m, in \u001B[36mNeptuneBase._add_entities\u001B[39m\u001B[34m(self, to_be_added, user_id, entity_type_map)\u001B[39m\n\u001B[32m    238\u001B[39m     destination_node_search_result = \u001B[38;5;28mself\u001B[39m._search_destination_node(dest_embedding, user_id, threshold=\u001B[32m0.9\u001B[39m)\n\u001B[32m    240\u001B[39m     cypher, params = \u001B[38;5;28mself\u001B[39m._add_entities_cypher(\n\u001B[32m    241\u001B[39m         source_node_search_result,\n\u001B[32m    242\u001B[39m         source,\n\u001B[32m   (...)\u001B[39m\u001B[32m    250\u001B[39m         user_id,\n\u001B[32m    251\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m252\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgraph\u001B[49m\u001B[43m.\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcypher\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m=\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    253\u001B[39m     results.append(result)\n\u001B[32m    254\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m results\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/git/acarbonetto/mem0/.venv/lib/python3.11/site-packages/langchain_aws/graphs/neptune_graph.py:470\u001B[39m, in \u001B[36mNeptuneGraph.query\u001B[39m\u001B[34m(self, query, params)\u001B[39m\n\u001B[32m    466\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.client.execute_open_cypher_query(openCypherQuery=query)[\n\u001B[32m    467\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mresults\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    468\u001B[39m         ]\n\u001B[32m    469\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m--> \u001B[39m\u001B[32m470\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m NeptuneQueryException(\n\u001B[32m    471\u001B[39m         {\n\u001B[32m    472\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mmessage\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33mAn error occurred while executing the query.\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    473\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mdetails\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[32m    474\u001B[39m         }\n\u001B[32m    475\u001B[39m     )\n",
      "\u001B[31mNeptuneQueryException\u001B[39m: {'message': 'An error occurred while executing the query.', 'details': \"An error occurred (MalformedQueryException) when calling the ExecuteOpenCypherQuery operation: Invalid input '~': expected whitespace, comment or a property key name (line 2, column 76 (offset: 76))\"}"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Explorer Visualization\n",
    "\n",
    "You can visualize the graph using a Graph Explorer connection to Neptune Analytics in Neptune Notebooks in the Amazon console.  See [Using Amazon Neptune with graph notebooks](https://docs.aws.amazon.com/neptune/latest/userguide/graph-notebooks.html) for instructions on how to setup a Neptune Notebook with Graph Explorer.\n",
    "\n",
    "Once the graph has been generated, you can open the visualization in the Neptune > Notebooks and click on Actions > Open Graph Explorer.  This will automatically connect to your neptune analytics graph that was provided in the notebook setup.\n",
    "\n",
    "Once in Graph Explorer, visit Open Connections and send all the available nodes and edges to Explorer. Visit Open Graph Explorer to see the nodes and edges in the graph.\n",
    "\n",
    "### Graph Explorer Visualization Example\n",
    "\n",
    "_Note that the visualization given below represents only a single example of the possible results generated by the LLM._\n",
    "\n",
    "Visualization for the relationship:\n",
    "```\n",
    "\"alice\" --plans_to_watch--> \"movie\"\n",
    "```\n",
    "\n",
    "![neptune-example-visualization-1.png](./neptune-example-visualization-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"How about a thriller movies? They can be quite engaging.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Store inferred memories (default behavior)\n",
    "result = m.add(messages, user_id=user_id, metadata={\"category\": \"movie_recommendations\"})\n",
    "\n",
    "all_results = m.get_all(user_id=user_id)\n",
    "for n in all_results[\"results\"]:\n",
    "    print(f\"node \\\"{n['memory']}\\\": [hash: {n['hash']}]\")\n",
    "\n",
    "for e in all_results[\"relations\"]:\n",
    "    print(f\"edge \\\"{e['source']}\\\" --{e['relationship']}--> \\\"{e['target']}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Explorer Visualization Example\n",
    "\n",
    "_Note that the visualization given below represents only a single example of the possible results generated by the LLM._\n",
    "\n",
    "Visualization for the relationship:\n",
    "```\n",
    "\"alice\" --plans_to_watch--> \"movie\"\n",
    "\"thriller\" --type_of--> \"movie\"\n",
    "\"movie\" --can_be--> \"engaging\"\n",
    "```\n",
    "\n",
    "![neptune-example-visualization-2.png](./neptune-example-visualization-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"I'm not a big fan of thriller movies but I love sci-fi movies.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Store inferred memories (default behavior)\n",
    "result = m.add(messages, user_id=user_id, metadata={\"category\": \"movie_recommendations\"})\n",
    "\n",
    "all_results = m.get_all(user_id=user_id)\n",
    "for n in all_results[\"results\"]:\n",
    "    print(f\"node \\\"{n['memory']}\\\": [hash: {n['hash']}]\")\n",
    "\n",
    "for e in all_results[\"relations\"]:\n",
    "    print(f\"edge \\\"{e['source']}\\\" --{e['relationship']}--> \\\"{e['target']}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Explorer Visualization Example\n",
    "\n",
    "_Note that the visualization given below represents only a single example of the possible results generated by the LLM._\n",
    "\n",
    "Visualization for the relationship:\n",
    "```\n",
    "\"alice\" --dislikes--> \"thriller_movies\"\n",
    "\"alice\" --loves--> \"sci-fi_movies\"\n",
    "\"alice\" --plans_to_watch--> \"movie\"\n",
    "\"thriller\" --type_of--> \"movie\"\n",
    "\"movie\" --can_be--> \"engaging\"\n",
    "```\n",
    "\n",
    "![neptune-example-visualization-3.png](./neptune-example-visualization-3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Got it! I'll avoid thriller recommendations and suggest sci-fi movies in the future.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Store inferred memories (default behavior)\n",
    "result = m.add(messages, user_id=user_id, metadata={\"category\": \"movie_recommendations\"})\n",
    "\n",
    "all_results = m.get_all(user_id=user_id)\n",
    "for n in all_results[\"results\"]:\n",
    "    print(f\"node \\\"{n['memory']}\\\": [hash: {n['hash']}]\")\n",
    "\n",
    "for e in all_results[\"relations\"]:\n",
    "    print(f\"edge \\\"{e['source']}\\\" --{e['relationship']}--> \\\"{e['target']}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Explorer Visualization Example\n",
    "\n",
    "_Note that the visualization given below represents only a single example of the possible results generated by the LLM._\n",
    "\n",
    "Visualization for the relationship:\n",
    "```\n",
    "\"alice\" --recommends--> \"sci-fi\"\n",
    "\"alice\" --dislikes--> \"thriller_movies\"\n",
    "\"alice\" --loves--> \"sci-fi_movies\"\n",
    "\"alice\" --plans_to_watch--> \"movie\"\n",
    "\"alice\" --avoids--> \"thriller\"\n",
    "\"thriller\" --type_of--> \"movie\"\n",
    "\"movie\" --can_be--> \"engaging\"\n",
    "\"sci-fi\" --type_of--> \"movie\"\n",
    "```\n",
    "\n",
    "![neptune-example-visualization-4.png](./neptune-example-visualization-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search memories\n",
    "\n",
    "Search all memories for \"what does alice love?\".  Since \"alice\" the user, this will search for a relationship that fits the users love of \"sci-fi\" movies and dislike of \"thriller\" movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = m.search(\"what does alice love?\", user_id=user_id)\n",
    "for result in search_results[\"results\"]:\n",
    "    print(f\"\\\"{result['memory']}\\\" [score: {result['score']}]\")\n",
    "for relation in search_results[\"relations\"]:\n",
    "    print(f\"{relation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.delete_all(user_id)\n",
    "m.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this example we demonstrated how an AWS tech stack can be used to store and retrieve memory context. Bedrock LLM models can be used to interpret given conversations.  OpenSearch can store text chunks with vector embeddings. Neptune Analytics can store the text chunks in a graph format with relationship entities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
